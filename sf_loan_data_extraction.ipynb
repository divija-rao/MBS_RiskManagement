{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dc2c26",
   "metadata": {},
   "source": [
    "*This Python script automates the extraction, cleaning, and consolidation of the extensive Freddie Mac Single-Family Loan-Level Dataset, a standard and widely-used resource in mortgage-backed securities analysis. Designed for computational efficiency, the code processes a decade of quarterly data (2014-2024) by systematically reading origination and performance files.Through a robust process of deduplication and merging, the script constructs a reliable panel dataset that serves as a critical input for forecasting loan performance and measuring portfolio risk.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b37b3",
   "metadata": {},
   "source": [
    "### **Origination Data**\n",
    "\n",
    "#### Within a Quarter:\n",
    "The origination file for each quarter contains unique Loan Sequence Number values specific to that quarter, as it records only new loans originated during that period.\n",
    "\n",
    "#### Across Quarters:\n",
    "Origination data across quarters (e.g., Q1, Q2, Q3, Q4) should generally be unique per loan, with each Loan Sequence Number assigned at origination and not reused.\n",
    "\n",
    "However, a loan might appear in multiple quarters’ origination files if:\n",
    " - Its details were revised (e.g., due to corrections or amendments).\n",
    " - Historical data is re-included in later quarters for completeness, though this is rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94411c5b",
   "metadata": {},
   "source": [
    "### **Performance Data**\n",
    "\n",
    "#### Within a Quarter:\n",
    "- The performance file for a given quarter includes multiple entries for the same Loan Sequence Number, representing monthly performance updates.\n",
    "- For example, a loan might have records for Monthly Reporting Period values like 202401 (January), 202402 (February), and 202403 (March) in Q1 2024.\n",
    "\n",
    "#### Across Quarters:\n",
    "- Performance data extends across multiple quarters, with a loan’s performance tracked in each quarter’s file up to the latest available data.\n",
    "- Performance data for a loan is tracked over time, but Freddie Mac provides it in a single performance file per origination quarter, not separate files for each reporting quarter.\n",
    "- For example, a loan originated in Q1 2024 will have all its performance records (e.g., January, February, March 2024, and continuing through the latest available data, such as March 2025) consolidated in the performance file tied to Q1 2024.\n",
    "- This means there are not multiple records per loan ID across separate quarterly performance files (e.g., one for Q2, Q3, Q4). Instead, the single performance file for the origination quarter contains all monthly updates up to the most recent data cutoff, avoiding duplication across quarters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b619b",
   "metadata": {},
   "source": [
    "### **Relationship Between Origination and Performance Data**\n",
    "\n",
    "#### Loan IDs in Performance vs. Origination: \n",
    "- The performance data for a specific quarter does not include Loan Sequence Numbers beyond those originated in its corresponding origination quarter.\n",
    "- Instead, each performance file (e.g., performance_2024Q2) is tied to the loans originated in that same quarter (e.g., origination_2024Q2) and tracks their performance from origination through the latest available data.\n",
    "- This means performance files are cohort-specific and do not aggregate loans from previous quarters.\n",
    "\n",
    "#### Merge Behavior\n",
    "- An inner merge (pd.merge(..., how='inner')) will match only the loans present in both the origination and performance files for that quarter, ensuring consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8aac61",
   "metadata": {},
   "source": [
    "### Data Extraction Code Approach\n",
    "\n",
    "- Process data quarterly across all years (2014-2024).\n",
    "- For origination data, keep the first instance of each Loan Sequence Number globally across all years and quarters.\n",
    "- For performance data, keep the last instance of each Loan Sequence Number globally across all years and quarters.\n",
    "- Use an inner join to merge origination and performance data.\n",
    "- Ensure computational efficiency given the large dataset size and quarterly separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ec08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c67d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the data folders and Excel layout file\n",
    "data_dir = '/Users/dr/Documents/GitHub/MBS_RiskManagement/data/'\n",
    "layout_file = '/Users/dr/Documents/GitHub/MBS_RiskManagement/READ_ME/SF LLD File Layout Release 44.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse sheet content from Excel\n",
    "def parse_sheet_from_excel(sheet_name):\n",
    "    df = pd.read_excel(layout_file, sheet_name=sheet_name, header=None)\n",
    "    columns = []\n",
    "    dtypes = {}\n",
    "    start_row = df.index[df[0].str.contains('FIELD POSITION', na=False)].tolist()\n",
    "    if start_row:\n",
    "        start_row = start_row[0] + 1\n",
    "    else:\n",
    "        start_row = 0\n",
    "    \n",
    "    for index, row in df.iloc[start_row:].iterrows():\n",
    "        if pd.isna(row[0]) or not isinstance(row[1], str):\n",
    "            break\n",
    "        attribute_name = row[1].strip()\n",
    "        data_type = row[2].strip() if pd.notna(row[2]) else 'object'\n",
    "        columns.append(attribute_name)\n",
    "        if 'Alpha' in data_type or 'Alpha Numeric' in data_type or '- PYYQnXXXXXXX' in data_type:\n",
    "            dtypes[attribute_name] = 'object'\n",
    "        elif 'Numeric' in data_type and not ' - ' in data_type:\n",
    "            dtypes[attribute_name] = 'Int64'\n",
    "        elif 'Numeric - ' in data_type:\n",
    "            dtypes[attribute_name] = 'float64'\n",
    "        elif 'Date' in data_type:\n",
    "            dtypes[attribute_name] = 'datetime64[ns]'\n",
    "        else:\n",
    "            dtypes[attribute_name] = 'object'\n",
    "    print(f\"{sheet_name} columns: {columns}\")\n",
    "    print(f\"{sheet_name} dtypes: {dtypes}\")\n",
    "    return columns, dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Origination and Performance sheets from Excel\n",
    "origination_columns, origination_dtypes = parse_sheet_from_excel('Origination Data File')\n",
    "performance_columns, performance_dtypes = parse_sheet_from_excel('Monthly Performance Data File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the extracted_data folder \n",
    "extracted_data_dir = os.path.join('/Users/dr/Documents/GitHub/MBS_RiskManagement/', 'extracted_data') \n",
    "os.makedirs(extracted_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_yyyymm(val):\n",
    "    \"\"\"Convert YYYYMM or YYYYMMDD strings into datetime.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return pd.NaT\n",
    "    val = str(val).strip()\n",
    "    if len(val) == 6:  # YYYYMM\n",
    "        return datetime.strptime(val, \"%Y%m\")\n",
    "    elif len(val) == 8:  # YYYYMMDD\n",
    "        return datetime.strptime(val, \"%Y%m%d\")\n",
    "    else:\n",
    "        return pd.to_datetime(val, errors=\"coerce\")  # fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years and quarters to process \n",
    "years = range(2014, 2025) # 2014 to 2024 inclusive \n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check available disk space \n",
    "def check_disk_space(path, required_mb=100): \n",
    "    stat = os.statvfs(path) \n",
    "    free_mb = (stat.f_bavail * stat.f_frsize) / (1024 * 1024) \n",
    "    if free_mb < required_mb: \n",
    "        print(f\"Warning: Only {free_mb:.1f} MB free on {path}. Need at least {required_mb} MB. Free up space or adjust output.\") \n",
    "        return False \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionaries to track first origination and last performance \n",
    "origination_first = {} \n",
    "performance_last = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each year and quarter\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        folder_path = os.path.join(data_dir, f'historical_data_{year}{quarter}')\n",
    "        \n",
    "        if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "            print(f\"Processing folder: {folder_path}\")\n",
    "            \n",
    "            # Check disk space before processing\n",
    "            if not check_disk_space(extracted_data_dir, required_mb=500):\n",
    "                break\n",
    "            \n",
    "            # ------------------------\n",
    "            # Process origination data\n",
    "            # ------------------------\n",
    "            origination_file_pattern = f'historical_data_{year}{quarter}.txt'\n",
    "            origination_file = os.path.join(folder_path, origination_file_pattern)\n",
    "\n",
    "            if os.path.exists(origination_file):\n",
    "                chunk_iterator = pd.read_csv(\n",
    "                    origination_file,\n",
    "                    sep='|',\n",
    "                    header=None,\n",
    "                    names=origination_columns,\n",
    "                    encoding='utf-8',\n",
    "                    dtype={col: 'object' for col in origination_columns},  # read everything as string first\n",
    "                    chunksize=100000,\n",
    "                    low_memory=False\n",
    "                )\n",
    "\n",
    "                for chunk in chunk_iterator:\n",
    "                    # Parse origination date columns\n",
    "                    for col in ['First Payment Date', 'Maturity Date']:\n",
    "                        if col in chunk.columns:\n",
    "                            chunk[col] = chunk[col].apply(parse_yyyymm)\n",
    "\n",
    "                    # Apply other dtypes\n",
    "                    for col, dtype in {k: v for k, v in origination_dtypes.items()\n",
    "                                       if k not in ['First Payment Date', 'Maturity Date']}.items():\n",
    "                        if col in chunk.columns:\n",
    "                            chunk[col] = chunk[col].astype(dtype, errors='ignore')\n",
    "\n",
    "                    # Keep FIRST occurrence per Loan ID (global)\n",
    "                    chunk = chunk.sort_values(['Loan Sequence Number', 'First Payment Date'])\n",
    "                    first_rows = chunk.groupby('Loan Sequence Number').head(1)\n",
    "                    for loan_id, row in first_rows.set_index('Loan Sequence Number').to_dict('index').items():\n",
    "                        if loan_id not in origination_first:\n",
    "                            origination_first[loan_id] = row\n",
    "            else:\n",
    "                print(f\"Origination file not found: {origination_file_pattern}\")\n",
    "\n",
    "            \n",
    "            # ------------------------\n",
    "            # Process performance data\n",
    "            # ------------------------\n",
    "            performance_file_pattern = f'historical_data_time_{year}{quarter}.txt'\n",
    "            performance_file = os.path.join(folder_path, performance_file_pattern)\n",
    "\n",
    "            if os.path.exists(performance_file):\n",
    "                chunk_iterator = pd.read_csv(\n",
    "                    performance_file,\n",
    "                    sep='|',\n",
    "                    header=None,\n",
    "                    names=performance_columns,\n",
    "                    encoding='utf-8',\n",
    "                    dtype={col: 'object' for col in performance_columns},  # read everything as string first\n",
    "                    chunksize=100000,\n",
    "                    low_memory=False\n",
    "                )\n",
    "        \n",
    "                for chunk in chunk_iterator:\n",
    "                    # Parse performance date columns\n",
    "                    for col in ['Monthly Reporting Period', 'Defect Settlement Date', \n",
    "                                'Zero Balance Effective Date', 'Due Date of Last Paid Installment (DDLPI)']:\n",
    "                        if col in chunk.columns:\n",
    "                            chunk[col] = chunk[col].apply(parse_yyyymm)\n",
    "\n",
    "                    # Apply other dtypes\n",
    "                    for col, dtype in {k: v for k, v in performance_dtypes.items()\n",
    "                                       if col not in ['Monthly Reporting Period', 'Defect Settlement Date',\n",
    "                                                      'Zero Balance Effective Date', 'Due Date of Last Paid Installment (DDLPI)']}.items():\n",
    "                        if col in chunk.columns:\n",
    "                            chunk[col] = chunk[col].astype(dtype, errors='ignore')\n",
    "\n",
    "                    # Keep LAST occurrence per Loan ID (global)\n",
    "                    chunk = chunk.sort_values(['Loan Sequence Number', 'Monthly Reporting Period'])\n",
    "                    last_rows = chunk.groupby('Loan Sequence Number').tail(1)\n",
    "                    performance_last.update(last_rows.set_index('Loan Sequence Number').to_dict('index'))\n",
    "            else:\n",
    "                print(f\"Performance file not found: {performance_file_pattern}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert global dictionaries to DataFrames\n",
    "df_origination = pd.DataFrame.from_dict(origination_first, orient='index')\n",
    "df_performance = pd.DataFrame.from_dict(performance_last, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join on Loan Sequence Number\n",
    "merged = df_origination.merge(df_performance, \n",
    "                              left_index=True, \n",
    "                              right_index=True, \n",
    "                              how='inner', \n",
    "                              suffixes=('_orig', '_perf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b910e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save final merged dataset\n",
    "output_file = os.path.join(extracted_data_dir, \"merged_loans_2014_2024.csv\")\n",
    "merged.to_csv(output_file, index=True)\n",
    "\n",
    "print(f\"Final merged dataset written to: {output_file}\")\n",
    "print(f\"Total loans in merged set: {len(merged)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
